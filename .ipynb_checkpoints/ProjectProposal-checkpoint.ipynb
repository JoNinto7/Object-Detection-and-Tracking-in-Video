{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e2f729-5390-4a8c-80d9-fc356b499e66",
   "metadata": {},
   "source": [
    "# Object Detection and Tracking in Video Using Custom CNN and SORT  \n",
    "**Authors: Joseph Nikhil Reddy Maramreddy(yue15) and Chinmayi Supraja Pandamaneni(knl114)**\n",
    "\n",
    "## Project Summary  \n",
    "This project aims to build an end-to-end system that performs object detection and tracking on benchmark video datasets. A custom Convolutional Neural Network (CNN) will be trained from scratch for object detection, and the SORT (Simple Online Realtime Tracker) algorithm will be integrated to assign unique IDs and track detected objects across frames. We will use the EVT100 dataset from CVPR 2024 for evaluation. The goal is to demonstrate a complete vision pipeline without relying on pretrained models (except for baseline comparison), and to evaluate our model using standard tracking metrics.\n",
    "\n",
    "## Problem Statement  \n",
    "Build a system capable of detecting and tracking multiple objects in video data. We will train our own object detector and integrate it with SORT for object tracking.\n",
    "\n",
    "**Benchmark:** EVT100 (CVPR 2024) â€” selected due to its high-resolution videos, recent usage in research, and strong annotation quality.\n",
    "\n",
    "**Data Characteristics:** EVT100 includes labeled video sequences with bounding boxes and object IDs, allowing us to train and evaluate both detection and tracking components. We aim to achieve accurate multi-object tracking measured by mAP and MOTA.\n",
    "\n",
    "## Dataset  \n",
    "The EVT100 benchmark dataset contains:\n",
    "- 100 high-resolution video sequences\n",
    "- Bounding boxes and object IDs for annotated frames\n",
    "- Event-based and RGB video data\n",
    "\n",
    "We will use only the RGB video sequences for this project. The dataset enables training and evaluating object detectors in a realistic, dynamic setting. It saves significant time otherwise spent on manual labeling, making it feasible to meet our project timeline.\n",
    "\n",
    "**We are using EVT100 because:**\n",
    "- It is recent (CVPR 2024)  \n",
    "- Includes diverse and high-resolution scenes  \n",
    "- Comes with complete tracking annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d413b8-9b18-4160-9496-58ae4add48e4",
   "metadata": {},
   "source": [
    "## Feedback and Research Summary\n",
    "\n",
    "We approached the instructor after Spring Break via Teams and received valuable feedback. Initially, we planned to use self-recorded videos, but were advised to use benchmark datasets with existing annotations to save time. Based on this, we evaluated several popular object tracking benchmarks including MOT17, KITTI, GOT-10k, and EVT100.\n",
    "\n",
    "**After reviewing these options, we selected EVT100 because:**\n",
    "- It is a recent benchmark (CVPR 2024)\n",
    "- It offers high-resolution RGB videos\n",
    "- It includes full object tracking annotations\n",
    "\n",
    "We may use pretrained models as starting points and baselines but will focus on fine-tuning and integrating them effectively within our pipeline. Our research focused on learning how CNNs are structured and trained (using concepts from class), as well as how tracking algorithms like SORT (which combines Kalman Filters and Hungarian matching) operate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
